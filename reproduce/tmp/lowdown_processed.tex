
\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Computational reproduction is the process of reproducing the results of a scientific paper using the data and code provided by the authors of the paper. This subject sits within the broader context of ``reproducibility'' in scientific  research, which is the idea that scientific results should be reproducible by other scientists. Concepts around reproducibility have been core to the philosophy of science for decades, but several aspects of the scientific method have been challenged by recent developments. 
First, recent conversations around $p$-hacking and fraud in scientific publishing have led to a ``crisis'' at the core of of social science centered around the role of human error, guile, and incentives. 
Additionally , the increasing computational complexity of scientific research has led to a new set of challenges. Chief among these is the fact that the results of many scientific papers are not reproducible to even the lowest degree. This is because the data and code used to produce the results are not made available to the public.

advent of computational science has brought new challenges to the field.

At the heart of the concern with research by ousted Stanford president Mark is the fact that it is impossible to verify whether the images produced in the paper are fabricated or actually generated by the scientific equipment they claimed to use in the published manuscript.

Platform-independent reproducible execution

Economically feasibility

this is known as the \href{https://en.wikipedia.org/wiki/Replication_crisis}{reproducibility crisis}.

An increasing number of journals 

While some initiatives have emerged to facilitate computational reproduction, there is no widely accepted standard for computational reproduction. 

Lay readers may be surprised to learn that the results of many scientific papers are not reproducible to even the lowest degree. (We put forward the following standard as the first of computational reproducibility: ``More than one person verified that the results in the published paper match the results of the code and data provided by the authors.'') 

This is because the data and code used to produce the results are not made available to the public. 

such as the \href{https://rescience.github.io/}{ReScience journal} and \href{https://jupyterbook.org/en/stable/content/myst.html}{MyST Markdown}

While many advocate for the value of peer review in scientific publishing, as of 2023, there no scientific standard exists for true computational reproducibility. 

This is a problem because it means that the quality of peer review varies from journal to journal, and even from paper to paper. 

the most promising avenue might be emphasizing the importance of collaboration and transparency. By fostering a culture where researchers work together, openly share data and findings, and commit to thorough documentation, the reliability and replicability of work can be increased.

In the coming era, science must not be buoyed by computational power alone, but also by a culture of rigor, collaboration, and transparency.
, the challenge lies not just in advancing science but in ensuring its very foundation remains robust, trustworthy, and verifiable. 
