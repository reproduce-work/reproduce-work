{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dynamic\n",
    "\n",
    "> This code helps users automatically save, timestamp, and eventually source trace a specific set of data for publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "def read_base_config():\n",
    "    with open(Path(reproduce_dir, 'config.toml'), 'r') as f:\n",
    "        base_config = toml.load(f)\n",
    "    return base_config\n",
    "\n",
    "def update_watched_files(add=[], remove=[]):\n",
    "    base_config = read_base_config()\n",
    "    existing_files = base_config['repro']['files']['watch']\n",
    "    new_files = existing_files + [a for a in add if a not in existing_files]\n",
    "    new_files = [f for f in new_files if f not in remove]\n",
    "    base_config['repro']['files']['watch'] = new_files\n",
    "\n",
    "    current_develop_script = base_config['repro']['stage']['develop']['script']\n",
    "    current_develop_script\n",
    "    # regex to replace content in string matching 'watcher \\\"{to_replace}\\\"'\n",
    "    # with 'watcher \\\"{new_files}\\\"'\n",
    "    # and replace 'build_cmd' with 'python reproduce_work.build()'\n",
    "    import re\n",
    "    new_develop_script = re.sub(\n",
    "        r'watcher \\\"(.*?)\\\"', \n",
    "        f'watcher \\\"{\",\".join(new_files)}\\\"', \n",
    "        current_develop_script\n",
    "    )\n",
    "    base_config['repro']['stage']['develop']['script'] = new_develop_script\n",
    "\n",
    "    with open(Path(reproduce_dir, 'config.toml'), 'w') as f:\n",
    "        toml.dump(base_config, f)\n",
    "        \n",
    "    print(f\"Updated watched files to {new_files}\")\n",
    "    return new_files\n",
    "\n",
    "def validate_base_config(base_config):\n",
    "    required_keys = ['authors', 'repro']\n",
    "    for key in required_keys:\n",
    "        if key not in base_config:\n",
    "            print(toml.dumps(base_config))\n",
    "            print(f\"Error: Missing required field '{key}' in config.toml\")\n",
    "            return False\n",
    "        if key=='repro':\n",
    "            if 'stages' not in base_config['repro']:\n",
    "                print(f\"Error: Missing required field 'repro.stages' in reproduce.work configuration at {reproduce_dir}/config.toml\")\n",
    "                return False\n",
    "            for stage in base_config['repro']['stages']:\n",
    "                if (f'repro.stage.{stage}' not in base_config) and (stage not in base_config['repro']['stage']):\n",
    "                    print(toml.dumps(base_config))\n",
    "                    print(f\"Error: Missing required field repro.stage.{stage} in reproduce.work configuration at {reproduce_dir}/config.toml\")\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "def requires_config(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        config = read_base_config()\n",
    "        if not validate_base_config(config):\n",
    "            raise Exception(\"Your reproduce.work configuration is not valid.\")\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "VAR_REGISTRY = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import inspect\n",
    "import re\n",
    "import toml\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#def update_registry(var_name, value):\n",
    "    \n",
    "\n",
    "def get_cell_index():\n",
    "    \"\"\"\n",
    "    Get the current cell index in a Jupyter notebook environment.\n",
    "    If not in Jupyter, return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Execute JavaScript to get the current cell index\n",
    "        get_ipython().run_cell_magic('javascript', '', 'IPython.notebook.kernel.execute(\\'current_cell_index = \\' + IPython.notebook.get_selected_index())')\n",
    "        return current_cell_index\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def check_for_defintion_in_context(function_name='save'):\n",
    "    assert function_name in ['save', 'assign'], \"function_name must be either 'save' or 'assign'\"\n",
    "    \n",
    "    from IPython import get_ipython\n",
    "    ip = get_ipython()\n",
    "\n",
    "    # Check if in Jupyter environment\n",
    "    if ip is None:\n",
    "        \n",
    "        #fill this in \n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        # Get the input history\n",
    "        #lineno = inspect.stack()[0].lineno\n",
    "        raw_hist = ip.history_manager.input_hist_raw\n",
    "        current_cell = raw_hist[-1]\n",
    "\n",
    "\n",
    "        matches = re.findall(rf\"{function_name}\\((.+?),\", current_cell)\n",
    "                \n",
    "        if matches:\n",
    "            # save call\n",
    "            defined_var = matches[0].strip()\n",
    "            definition_cell_content = ''\n",
    "            \n",
    "            for prior_cell in raw_hist[-2::-1]:\n",
    "                #print(prior_cell)\n",
    "                if f'{defined_var} =' in prior_cell or f'{defined_var}=' in prior_cell:\n",
    "                    definition_cell_content = prior_cell\n",
    "                    break\n",
    "            \n",
    "            # find the line number of the where the variable was defined\n",
    "            # Give a window of 5 lines around the definition call\n",
    "            def_cell_lines = definition_cell_content.split('\\n')\n",
    "            if len(def_cell_lines)>0:\n",
    "                lineno = None\n",
    "                for line_num, line in enumerate(def_cell_lines):\n",
    "                    if defined_var in line:\n",
    "                        lineno = line_num\n",
    "                        break\n",
    "                if lineno:\n",
    "                    definition_context = (\n",
    "                        '\\n'.join(def_cell_lines[max(0, lineno-5):lineno]) + \n",
    "                        '\\nFLAG' + def_cell_lines[lineno] + '\\n' +\n",
    "                        '\\n'.join(def_cell_lines[lineno+1:min(len(def_cell_lines), lineno+5)])\n",
    "                    )\n",
    "                else:\n",
    "                    definition_context = None\n",
    "\n",
    "            else:\n",
    "                definition_context = None\n",
    "\n",
    "            \n",
    "            save_cell_lines = current_cell.split('\\n')\n",
    "            if len(save_cell_lines)>0:\n",
    "                save_lineno = None\n",
    "                for line_num, line in enumerate(save_cell_lines):\n",
    "                    if 'save(' in line:\n",
    "                        save_lineno = line_num\n",
    "                        break\n",
    "                \n",
    "                if save_lineno:\n",
    "                    save_context = (\n",
    "                        '\\n'.join(save_cell_lines[max(0, save_lineno-5):save_lineno]) + \n",
    "                        '\\nFLAG' + save_cell_lines[save_lineno] + '\\n' +\n",
    "                        '\\n'.join(save_cell_lines[save_lineno+1:min(len(save_cell_lines), save_lineno+5)])\n",
    "                    )\n",
    "                else:\n",
    "                    save_context = None\n",
    "                \n",
    "            else:\n",
    "                save_context = None\n",
    "            \n",
    "\n",
    "        else:\n",
    "            # not a save call\n",
    "            save_context = None\n",
    "            definition_context = None\n",
    "\n",
    "        return(save_context, definition_context)\n",
    "\n",
    "\n",
    "class ReproduceWorkEncoder(toml.TomlEncoder):\n",
    "    def dump_str(self, v):\n",
    "        \"\"\"Encode a string.\"\"\"\n",
    "        if \"\\n\" in v:\n",
    "            return v  # If it's a multi-line string, return it as-is\n",
    "        return super().dump_str(v)\n",
    "    \n",
    "    def dump_value(self, v):\n",
    "        \"\"\"Determine the type of a Python object and serialize it accordingly.\"\"\"\n",
    "        if isinstance(v, str) and \"\\n\" in v:\n",
    "            return '\"\"\"\\n' + v.strip() + '\\n' + '\"\"\"'\n",
    "        return super().dump_value(v)\n",
    "\n",
    "\n",
    "def serialize_to_toml(data, root=True):\n",
    "    \"\"\"Unified function to serialize various Python data types to TOML format.\"\"\"\n",
    "    toml_string = \"\"\n",
    "    \n",
    "    # Handle numpy array\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return f\"array = {data.tolist()}\"\n",
    "    \n",
    "    # Handle pandas DataFrame\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        toml_string += \"[dataframe]\\n\"\n",
    "        for col in data.columns:\n",
    "            values = data[col].tolist()\n",
    "            if all(isinstance(val, (int, float)) for val in values):\n",
    "                toml_string += f\"{col} = {values}\\n\"\n",
    "            else:\n",
    "                values_str = ['\"' + str(val) + '\"' for val in values]\n",
    "                toml_string += f\"{col} = [{', '.join(values_str)}]\\n\"\n",
    "        return toml_string\n",
    "    \n",
    "    # Handle dictionary\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, str):\n",
    "                toml_string += f\"{key} = \\\"{value}\\\"\\n\"\n",
    "            elif isinstance(value, (int, float)):\n",
    "                toml_string += f\"{key} = {value}\\n\"\n",
    "            elif isinstance(value, bool):\n",
    "                toml_string += f\"{key} = {str(value).lower()}\\n\"\n",
    "            elif isinstance(value, (list, set, tuple)):\n",
    "                values = \", \".join([str(v) for v in value])\n",
    "                toml_string += f\"{key} = [{values}]\\n\"\n",
    "            elif value is None:\n",
    "                toml_string += f\"{key} = null\\n\"\n",
    "            elif isinstance(value, (np.datetime64, pd.Timestamp)):\n",
    "                toml_string += f\"{key} = \\\"{str(value)}\\\"\\n\"\n",
    "            elif isinstance(value, dict) or isinstance(value, pd.DataFrame):\n",
    "                # Recursive call for nested dictionaries or DataFrames\n",
    "                nested_str = serialize_to_toml(value, root=False)\n",
    "                toml_string += f\"[{key}]\\n{nested_str}\\n\"\n",
    "    \n",
    "    # If it's the root call, remove any trailing newline\n",
    "    if root:\n",
    "        toml_string = toml_string.rstrip()\n",
    "    return toml_string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@requires_config\n",
    "def publish_data(content, name, metadata={}, watch=True):\n",
    "    \"\"\"\n",
    "    Save data to default data.toml file and register metadata.\n",
    "    \"\"\"\n",
    "    # Capture metadata\n",
    "    timestamp = datetime.datetime.now().isoformat()\n",
    "\n",
    "    # generate cryptographic hash of file contents\n",
    "    content_hash = hashlib.md5(str(content).encode('utf-8')).hexdigest()\n",
    "    timed_hash = hashlib.md5((str(content) + timestamp).encode('utf-8')).hexdigest()\n",
    "         \n",
    "    # Store metadata\n",
    "    new_metadata = {\n",
    "        \"type\": \"data\",\n",
    "        \"timestamp\": timestamp,\n",
    "        \"content_hash\": content_hash,\n",
    "        \"timed_hash\": timed_hash,\n",
    "    }\n",
    "\n",
    "    # detect if content var is of matplotlib or seaborn object type\n",
    "    if type(content).__name__ in ['Figure', 'AxesSubplot'] and 'savefig' in dir(content):\n",
    "        print('Saving serialized plot to SVG as file and in local data registry.')\n",
    "        # Serialize plot to SVG\n",
    "        buffer = io.BytesIO()\n",
    "        content.savefig(buffer, format='svg')\n",
    "        svg_data = buffer.getvalue()\n",
    "        buffer.close()\n",
    "\n",
    "        # Save SVG to file\n",
    "        svg_filename = filename.replace('.py', '.svg')\n",
    "        with open(svg_filename, 'wb') as file:\n",
    "            file.write(svg_data)\n",
    "\n",
    "        # Save SVG to registry\n",
    "        metadata['plot'] = svg_data.decode()\n",
    "\n",
    "    base_config = read_base_config()\n",
    "    metadata.update(new_metadata)\n",
    "\n",
    "    metadata['value'] = content\n",
    "\n",
    "    # Save content to the default data.toml file\n",
    "    with open(Path(reproduce_dir, 'data.toml'), 'a') as file:\n",
    "        file.write(f'\\n[{name}]\\n')\n",
    "        file.write(toml.dumps(content, encoder=ReproduceWorkEncoder()))\n",
    "\n",
    "\n",
    "    # For this demo, let's return the metadata (in practice, you might want to log it, save it to another file, etc.)\n",
    "    if watch:\n",
    "        update_watched_files(add=[Path(reproduce_dir, 'data.toml')])\n",
    "\n",
    "    # check if dynamic file exists\n",
    "    if not os.path.exists(Path(base_config['repro']['files']['dynamic'])):\n",
    "        with open(Path(base_config['repro']['files']['dynamic']), 'w') as file:\n",
    "            file.write(toml.dumps({}))\n",
    "\n",
    "    with open(Path(base_config['repro']['files']['dynamic']), 'r') as file:\n",
    "        dynamic_data = toml.load(file)\n",
    "        \n",
    "    dynamic_data[name] = metadata\n",
    "\n",
    "    with open(Path(base_config['repro']['files']['dynamic']), 'w') as file:\n",
    "        toml.dump(dynamic_data, file, encoder=ReproduceWorkEncoder())\n",
    "\n",
    "    return metadata\n",
    "    \n",
    "\n",
    "@requires_config\n",
    "def publish_file(filename, metadata={}, watch=True):\n",
    "    \"\"\"\n",
    "    Save content to a file and register metadata.\n",
    "    \"\"\"\n",
    "    # Save content to the specified file\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "    # Capture metadata\n",
    "    timestamp = datetime.datetime.now().isoformat()\n",
    "    script_filename = inspect.currentframe().f_back.f_code.co_filename\n",
    "    python_version = sys.version\n",
    "    platform_info = platform.platform()\n",
    "\n",
    "    # generate cryptographic hash of file contents\n",
    "    content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()\n",
    "    timed_hash = hashlib.md5((content + timestamp).encode('utf-8')).hexdigest()\n",
    "         \n",
    "    save_context, definition_context = check_for_defintion_in_context(function_name='save')\n",
    "\n",
    "    # Store metadata\n",
    "    new_metadata = {\n",
    "        \"type\": \"file\",\n",
    "        \"timestamp\": timestamp,\n",
    "        #\"script_filename\": script_filename,\n",
    "        #\"python_version\": python_version,\n",
    "        #\"platform_info\": platform_info,\n",
    "        \"content_hash\": content_hash,\n",
    "        \"timed_hash\": timed_hash,\n",
    "        #\"save_context\": save_context,\n",
    "        #\"definition_context\": definition_context\n",
    "    }\n",
    "    cell_index = get_cell_index()\n",
    "    if cell_index:\n",
    "        new_metadata[\"cell_index\"] = cell_index\n",
    "\n",
    "    base_config = read_base_config()\n",
    "    #reproduce_work_watched_files = base_config['repro.files.watch']\n",
    "\n",
    "    metadata.update(new_metadata)\n",
    "\n",
    "    # For this demo, let's return the metadata (in practice, you might want to log it, save it to another file, etc.)\n",
    "    if watch:\n",
    "        update_watched_files(add=[filename])\n",
    "\n",
    "    # check if dynamic file exists\n",
    "    if not os.path.exists(Path(base_config['repro']['files']['dynamic'])):\n",
    "        with open(Path(base_config['repro']['files']['dynamic']), 'w') as file:\n",
    "            file.write(toml.dumps({}))\n",
    "\n",
    "    with open(Path(base_config['repro']['files']['dynamic']), 'r') as file:\n",
    "        dynamic_data = toml.load(file)\n",
    "        \n",
    "    dynamic_data[filename] = metadata\n",
    "\n",
    "    with open(Path(base_config['repro']['files']['dynamic']), 'w') as file:\n",
    "        toml.dump(dynamic_data, file, encoder=ReproduceWorkEncoder())\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "\n",
    "def reproducible(var_assignment_func):\n",
    "    \"\"\"\n",
    "    A decorator to register the line number and timestamp when a variable is assigned.\n",
    "    \"\"\"\n",
    "    def wrapper(value, var_name):\n",
    "        # Get the current frame and line number\n",
    "        frame = inspect.currentframe()\n",
    "        line_number = frame.f_back.f_lineno\n",
    "        \n",
    "        # Get the current timestamp\n",
    "        timestamp = datetime.datetime.now().isoformat()\n",
    "        \n",
    "        # Get the filename of the caller\n",
    "        filename = frame.f_back.f_code.co_filename\n",
    "        \n",
    "        # Execute the variable assignment function\n",
    "        var_assignment_func(var_name, value)\n",
    "\n",
    "        #save_context, definition_context = check_for_defintion_in_context(function_name='assign')\n",
    "        \n",
    "        # Register the variable name, line number, timestamp, and filename\n",
    "        VAR_REGISTRY[var_name] = {\n",
    "            \"type\": \"string\",\n",
    "            #\"line_number\": line_number,\n",
    "            \"timestamp\": timestamp,\n",
    "            #\"filename\": filename,\n",
    "            #\"save_context\": save_context,\n",
    "            #\"definition_context\": definition_context\n",
    "        }\n",
    "        cell_index = get_cell_index()\n",
    "        if cell_index:\n",
    "            VAR_REGISTRY[var_name][\"cell_index\"] = cell_index\n",
    "\n",
    "        if type(value) is not str:\n",
    "            value = str(value)\n",
    "            print(f\"WARNING: value of {var_name} was not a string. Converted to string: {value}.\")\n",
    "        \n",
    "        VAR_REGISTRY[var_name]['value'] = value\n",
    "\n",
    "        config = read_base_config()\n",
    "\n",
    "\n",
    "        # check if dynamic file exists\n",
    "        if not os.path.exists(Path(config['repro']['files']['dynamic'])):\n",
    "            with open(Path(config['repro']['files']['dynamic']), 'w') as file:\n",
    "                file.write(toml.dumps({}))\n",
    "        with open(Path(config['repro']['files']['dynamic']), 'r') as file:\n",
    "            dynamic_data = toml.load(file)\n",
    "            \n",
    "        dynamic_data[var_name] = VAR_REGISTRY[var_name]\n",
    "        \n",
    "        with open(Path(config['repro']['files']['dynamic']), 'w') as file:\n",
    "            toml.dump(dynamic_data, file, encoder=ReproduceWorkEncoder())\n",
    "\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "@reproducible\n",
    "def publish_variable(value, var_name):\n",
    "    globals()[var_name] = value\n",
    "\n",
    "# Test code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.kernel.execute('current_cell_index = ' + IPython.notebook.get_selected_index())",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: value of test_var_timestamp_1 was not a string. Converted to string: 67890.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "IPython.notebook.kernel.execute('current_cell_index = ' + IPython.notebook.get_selected_index())",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_var_timestamp_1': {'type': 'string',\n",
       "  'timestamp': '2023-10-02T02:11:07.000298',\n",
       "  'value': '67890'},\n",
       " 'test_var_timestamp_2': {'type': 'string',\n",
       "  'timestamp': '2023-10-02T02:11:07.016404',\n",
       "  'value': 'Hello again!'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish_variable(67890, \"test_var_timestamp_1\")  # This should capture this line number and timestamp\n",
    "publish_variable(\"Hello again!\", \"test_var_timestamp_2\")  # And this line number and timestamp\n",
    "\n",
    "VAR_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = \"John\"\n",
      "age = 28\n",
      "is_student = False\n",
      "scores = [85, 90, 78, 92]\n",
      "birthday = \"2000-01-01 00:00:00\"\n",
      "[df]\n",
      "[dataframe]\n",
      "A = [1, 2, 3]\n",
      "B = [\"a\", \"b\", \"c\"]\n",
      "date = [\"2022-01-01 00:00:00\", \"2022-01-02 00:00:00\", \"2022-01-03 00:00:00\"]\n",
      "\n",
      "[nested_dict]\n",
      "key1 = \"value1\"\n",
      "[sub_dict]\n",
      "sub_key = \"sub_value\"\n",
      "\n",
      "\n",
      "none_value = null\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the unified function\n",
    "data_sample = {\n",
    "    'name': 'John',\n",
    "    'age': 28,\n",
    "    'is_student': False,\n",
    "    'scores': [85, 90, 78, 92],\n",
    "    'birthday': pd.Timestamp('2000-01-01'),\n",
    "    'matrix': np.array([[1, 2], [3, 4]]),\n",
    "    'df': pd.DataFrame({\n",
    "        'A': [1, 2, 3],\n",
    "        'B': ['a', 'b', 'c'],\n",
    "        'date': [pd.Timestamp('2022-01-01'), pd.Timestamp('2022-01-02'), pd.Timestamp('2022-01-03')]\n",
    "    }),\n",
    "    'nested_dict': {\n",
    "        'key1': 'value1',\n",
    "        'sub_dict': {\n",
    "            'sub_key': 'sub_value'\n",
    "        }\n",
    "    },\n",
    "    'none_value': None\n",
    "}\n",
    "\n",
    "toml_representation = serialize_to_toml(data_sample)\n",
    "print(toml_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_var_timestamp_1]\n",
      "type = \"string\"\n",
      "timestamp = \"2023-10-02T02:11:07.000298\"\n",
      "value = \"67890\"\n",
      "\n",
      "[test_var_timestamp_2]\n",
      "type = \"string\"\n",
      "timestamp = \"2023-10-02T02:11:07.016404\"\n",
      "value = \"Hello again!\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = read_base_config()\n",
    "print(toml.dumps(VAR_REGISTRY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the save function\n",
    "test_content = \"This is a test content for the save function.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.kernel.execute('current_cell_index = ' + IPython.notebook.get_selected_index())",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated watched files to ['reproduce/main.md', 'reproduce/data.toml', 'reproduce/latex/template.tex', 'saved_file.txt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'file',\n",
       " 'timestamp': '2023-10-02T02:11:11.082654',\n",
       " 'content_hash': 'd1866c6aa7d10eb57a35cc88a77802c5',\n",
       " 'timed_hash': 'f9293765bd6cc1e991407203aa7da511'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = save(test_content, \"saved_file.txt\")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "#x = 10\n",
    "#y = \"Hello\"\n",
    "#z = [1, 2, 3]\n",
    "#save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
