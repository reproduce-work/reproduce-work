{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dynamic\n",
    "\n",
    "> This code helps users automatically save, timestamp, and eventually source trace a specific set of data for publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting reproduce.work config dir to ./reproduce\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import functools\n",
    "\n",
    "load_dotenv()\n",
    "def set_default_dir():\n",
    "    print('Setting reproduce.work config dir to ./reproduce')\n",
    "    return Path(\"./reproduce\")\n",
    "\n",
    "reproduce_dir = os.getenv(\"REPROWORKDIR\", set_default_dir())\n",
    "dev_image_tag = os.getenv(\"REPRODEVIMAGE\")\n",
    "\n",
    "def read_base_config():\n",
    "    with open(Path(reproduce_dir, 'config.toml'), 'r') as f:\n",
    "        base_config = toml.load(f)\n",
    "    return base_config\n",
    "\n",
    "def update_watched_files(add=[], remove=[]):\n",
    "    base_config = read_base_config()\n",
    "    existing_files = base_config['repro']['files']['watch']\n",
    "    new_files = existing_files + [a for a in add if a not in existing_files]\n",
    "    new_files = [f for f in new_files if f not in remove]\n",
    "    base_config['repro']['files']['watch'] = new_files\n",
    "\n",
    "    current_develop_script = base_config['repro']['stage']['develop']['script']\n",
    "    current_develop_script\n",
    "    # regex to replace content in string matching 'watcher \\\"{to_replace}\\\"'\n",
    "    # with 'watcher \\\"{new_files}\\\"'\n",
    "    # and replace 'build_cmd' with 'python reproduce_work.build()'\n",
    "    import re\n",
    "    new_develop_script = re.sub(\n",
    "        r'watcher \\\"(.*?)\\\"', \n",
    "        f'watcher \\\"{\",\".join(new_files)}\\\"', \n",
    "        current_develop_script\n",
    "    )\n",
    "    base_config['repro']['stage']['develop']['script'] = new_develop_script\n",
    "\n",
    "    with open(Path(reproduce_dir, 'config.toml'), 'w') as f:\n",
    "        toml.dump(base_config, f)\n",
    "        \n",
    "    if base_config['repro']['verbose']:\n",
    "        print(f\"Updated watched files to {new_files}\")\n",
    "    return new_files\n",
    "\n",
    "def validate_base_config(base_config):\n",
    "    required_keys = ['authors', 'repro']\n",
    "    for key in required_keys:\n",
    "        if key not in base_config:\n",
    "            print(toml.dumps(base_config))\n",
    "            print(f\"Error: Missing required field '{key}' in config.toml\")\n",
    "            return False\n",
    "        if key=='repro':\n",
    "            if 'stages' not in base_config['repro']:\n",
    "                print(f\"Error: Missing required field 'repro.stages' in reproduce.work configuration at {reproduce_dir}/config.toml\")\n",
    "                return False\n",
    "            for stage in base_config['repro']['stages']:\n",
    "                if (f'repro.stage.{stage}' not in base_config) and (stage not in base_config['repro']['stage']):\n",
    "                    print(toml.dumps(base_config))\n",
    "                    print(f\"Error: Missing required field repro.stage.{stage} in reproduce.work configuration at {reproduce_dir}/config.toml\")\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "def requires_config(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        config = read_base_config()\n",
    "        if not validate_base_config(config):\n",
    "            raise Exception(\"Your reproduce.work configuration is not valid.\")\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "VAR_REGISTRY = {\n",
    "    'REPROWORK_REMOTE_URL': None,\n",
    "    'REPROWORK_ACTIVE_NOTEBOOK': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def reproducible_old(var_assignment_func):\n",
    "    \"\"\"\n",
    "    A decorator to register the line number and timestamp when a variable is assigned.\n",
    "    \"\"\"\n",
    "    @functools.wraps(var_assignment_func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Extract value and var_name from args\n",
    "        # Assumes the decorated function always takes at least two arguments: value and var_name\n",
    "        value, var_name = args[0], args[1]\n",
    "\n",
    "        # Extract metadata from kwargs or default to an empty dictionary\n",
    "        metadata = kwargs.get('metadata', {})\n",
    "\n",
    "        # Get the current frame and line number\n",
    "        frame = inspect.currentframe()\n",
    "        line_number = frame.f_back.f_lineno\n",
    "\n",
    "        # Get the current timestamp\n",
    "        timestamp = datetime.datetime.now().isoformat()\n",
    "\n",
    "        # Get the filename of the caller\n",
    "        filename = frame.f_back.f_code.co_filename\n",
    "\n",
    "        # Execute the variable assignment function\n",
    "        result = var_assignment_func(*args, **kwargs)\n",
    "\n",
    "        # Register the variable name, line number, timestamp, and filename\n",
    "        VAR_REGISTRY[var_name] = {\n",
    "            \"type\": \"string\",\n",
    "            \"timestamp\": timestamp,\n",
    "        }\n",
    "\n",
    "        if type(value) is not str:\n",
    "            value = str(value)\n",
    "            print(f\"WARNING: value of {var_name} was not a string. Converted to string: {value}.\")\n",
    "\n",
    "        VAR_REGISTRY[var_name]['value'] = value\n",
    "\n",
    "        metadata.update(VAR_REGISTRY[var_name])\n",
    "\n",
    "        config = read_base_config()\n",
    "\n",
    "        # check if dynamic file exists\n",
    "        if not os.path.exists(Path(config['repro']['files']['dynamic'])):\n",
    "            with open(Path(config['repro']['files']['dynamic']), 'w') as file:\n",
    "                file.write(toml.dumps({}))\n",
    "        with open(Path(config['repro']['files']['dynamic']), 'r') as file:\n",
    "            dynamic_data = toml.load(file)\n",
    "\n",
    "        dynamic_data[var_name] = metadata\n",
    "\n",
    "        with open(Path(config['repro']['files']['dynamic']), 'w') as file:\n",
    "            toml.dump(dynamic_data, file, encoder=ReproduceWorkEncoder())\n",
    "\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "#@reproducible\n",
    "#def publish_variable(value, var_name, metadata={}):\n",
    "#    globals()[var_name] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import inspect\n",
    "import re\n",
    "import toml\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#def update_registry(var_name, value):\n",
    "    \n",
    "\n",
    "def get_cell_index():\n",
    "    \"\"\"\n",
    "    Get the current cell index in a Jupyter notebook environment.\n",
    "    If not in Jupyter, return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Execute JavaScript to get the current cell index\n",
    "        get_ipython().run_cell_magic('javascript', '', 'IPython.notebook.kernel.execute(\\'current_cell_index = \\' + IPython.notebook.get_selected_index())')\n",
    "        return current_cell_index\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def check_for_defintion_in_context(function_name='save'):\n",
    "    assert function_name in ['save', 'assign'], \"function_name must be either 'save' or 'assign'\"\n",
    "    \n",
    "    from IPython import get_ipython\n",
    "    ip = get_ipython()\n",
    "\n",
    "    # Check if in Jupyter environment\n",
    "    if ip is None:\n",
    "        \n",
    "        #fill this in \n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        # Get the input history\n",
    "        #lineno = inspect.stack()[0].lineno\n",
    "        raw_hist = ip.history_manager.input_hist_raw\n",
    "        current_cell = raw_hist[-1]\n",
    "\n",
    "\n",
    "        matches = re.findall(rf\"{function_name}\\((.+?),\", current_cell)\n",
    "                \n",
    "        if matches:\n",
    "            # save call\n",
    "            defined_var = matches[0].strip()\n",
    "            definition_cell_content = ''\n",
    "            \n",
    "            for prior_cell in raw_hist[-2::-1]:\n",
    "                #print(prior_cell)\n",
    "                if f'{defined_var} =' in prior_cell or f'{defined_var}=' in prior_cell:\n",
    "                    definition_cell_content = prior_cell\n",
    "                    break\n",
    "            \n",
    "            # find the line number of the where the variable was defined\n",
    "            # Give a window of 5 lines around the definition call\n",
    "            def_cell_lines = definition_cell_content.split('\\n')\n",
    "            if len(def_cell_lines)>0:\n",
    "                lineno = None\n",
    "                for line_num, line in enumerate(def_cell_lines):\n",
    "                    if defined_var in line:\n",
    "                        lineno = line_num\n",
    "                        break\n",
    "                if lineno:\n",
    "                    definition_context = (\n",
    "                        '\\n'.join(def_cell_lines[max(0, lineno-5):lineno]) + \n",
    "                        '\\nFLAG' + def_cell_lines[lineno] + '\\n' +\n",
    "                        '\\n'.join(def_cell_lines[lineno+1:min(len(def_cell_lines), lineno+5)])\n",
    "                    )\n",
    "                else:\n",
    "                    definition_context = None\n",
    "\n",
    "            else:\n",
    "                definition_context = None\n",
    "\n",
    "            \n",
    "            save_cell_lines = current_cell.split('\\n')\n",
    "            if len(save_cell_lines)>0:\n",
    "                save_lineno = None\n",
    "                for line_num, line in enumerate(save_cell_lines):\n",
    "                    if 'save(' in line:\n",
    "                        save_lineno = line_num\n",
    "                        break\n",
    "                \n",
    "                if save_lineno:\n",
    "                    save_context = (\n",
    "                        '\\n'.join(save_cell_lines[max(0, save_lineno-5):save_lineno]) + \n",
    "                        '\\nFLAG' + save_cell_lines[save_lineno] + '\\n' +\n",
    "                        '\\n'.join(save_cell_lines[save_lineno+1:min(len(save_cell_lines), save_lineno+5)])\n",
    "                    )\n",
    "                else:\n",
    "                    save_context = None\n",
    "                \n",
    "            else:\n",
    "                save_context = None\n",
    "            \n",
    "\n",
    "        else:\n",
    "            # not a save call\n",
    "            save_context = None\n",
    "            definition_context = None\n",
    "\n",
    "        return(save_context, definition_context)\n",
    "\n",
    "\n",
    "class ReproduceWorkEncoder(toml.TomlEncoder):\n",
    "    def dump_str(self, v):\n",
    "        \"\"\"Encode a string.\"\"\"\n",
    "        if \"\\n\" in v:\n",
    "            return v  # If it's a multi-line string, return it as-is\n",
    "        return super().dump_str(v)\n",
    "    \n",
    "    def dump_value(self, v):\n",
    "        \"\"\"Determine the type of a Python object and serialize it accordingly.\"\"\"\n",
    "        if isinstance(v, str) and \"\\n\" in v:\n",
    "            return '\"\"\"\\n' + v.strip() + '\\n' + '\"\"\"'\n",
    "        return super().dump_value(v)\n",
    "\n",
    "\n",
    "def serialize_to_toml(data, root=True):\n",
    "    \"\"\"Unified function to serialize various Python data types to TOML format.\"\"\"\n",
    "    toml_string = \"\"\n",
    "    \n",
    "    # Handle numpy array\n",
    "    if isinstance(data, np.ndarray):\n",
    "        toml_string += f\"array = {data.tolist()}\"\n",
    "    \n",
    "    # Handle pandas DataFrame\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        toml_string += \"[dataframe]\\n\"\n",
    "        for col in data.columns:\n",
    "            values = data[col].tolist()\n",
    "            if all(isinstance(val, (int, float)) for val in values):\n",
    "                toml_string += f\"{col} = {values}\\n\"\n",
    "            else:\n",
    "                values_str = ['\"' + str(val) + '\"' for val in values]\n",
    "                toml_string += f\"{col} = [{', '.join(values_str)}]\\n\"\n",
    "        return toml_string\n",
    "    \n",
    "    # Handle dictionary\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, str):\n",
    "                toml_string += f\"{key} = \\\"{value}\\\"\\n\"\n",
    "            elif isinstance(value, (int, float)):\n",
    "                toml_string += f\"{key} = {value}\\n\"\n",
    "            elif isinstance(value, bool):\n",
    "                toml_string += f\"{key} = {str(value).lower()}\\n\"\n",
    "            elif isinstance(value, (list, set, tuple)):\n",
    "                values = \", \".join([str(v) for v in value])\n",
    "                toml_string += f\"{key} = [{values}]\\n\"\n",
    "            elif value is None:\n",
    "                toml_string += f\"{key} = null\\n\"\n",
    "            elif isinstance(value, (np.datetime64, pd.Timestamp)):\n",
    "                toml_string += f\"{key} = \\\"{str(value)}\\\"\\n\"\n",
    "            elif isinstance(value, dict) or isinstance(value, pd.DataFrame):\n",
    "                # Recursive call for nested dictionaries or DataFrames\n",
    "                nested_str = serialize_to_toml(value, root=False)\n",
    "                toml_string += f\"[{key}]\\n{nested_str}\\n\"\n",
    "    \n",
    "    # If it's the root call, remove any trailing newline\n",
    "    if root:\n",
    "        toml_string = toml_string.rstrip()\n",
    "    return toml_string\n",
    "\n",
    "\n",
    "class ReproduceWorkEncoder(toml.TomlEncoder):\n",
    "    def dump_str(self, v):\n",
    "        \"\"\"Encode a string.\"\"\"\n",
    "        if \"\\n\" in v:\n",
    "            return v  # If it's a multi-line string, return it as-is\n",
    "        return super().dump_str(v)\n",
    "    \n",
    "    def dump_value(self, v):\n",
    "        \"\"\"Determine the type of a Python object and serialize it accordingly.\"\"\"\n",
    "        if isinstance(v, str) and \"\\n\" in v:\n",
    "            return '\"\"\"\\n' + v.strip() + '\\n' + '\"\"\"'\n",
    "        return super().dump_value(v)\n",
    "\n",
    "@requires_config\n",
    "def publish_data(content, name, metadata={}, watch=True):\n",
    "    \"\"\"\n",
    "    Save data to default pubdata.toml file and register metadata.\n",
    "    \"\"\"\n",
    "    # Capture metadata\n",
    "    timestamp = datetime.datetime.now().isoformat()\n",
    "    inspect_filename = inspect.currentframe().f_back.f_code.co_filename\n",
    "    python_version = sys.version.strip().replace('\\n', ' ')\n",
    "    platform_info = platform.platform()\n",
    "\n",
    "    # generate cryptographic hash of file contents\n",
    "    content_hash = hashlib.md5(str(content).encode('utf-8')).hexdigest()\n",
    "    timed_hash = hashlib.md5((str(content) + timestamp).encode('utf-8')).hexdigest()\n",
    "         \n",
    "    # Store metadata\n",
    "    new_metadata = {\n",
    "        \"type\": \"data\",\n",
    "        \"timestamp\": timestamp,\n",
    "        \"content_hash\": content_hash,\n",
    "        \"timed_hash\": timed_hash,\n",
    "        #\"python_version\": python_version,\n",
    "        #\"platform_info\": platform_info,\n",
    "    }\n",
    "    if VAR_REGISTRY['REPROWORK_REMOTE_URL']:\n",
    "        metadata['published_url'] = f\"{VAR_REGISTRY['REPROWORK_REMOTE_URL']}/{reproduce_dir}/pubdata.toml\"\n",
    "\n",
    "    if VAR_REGISTRY['REPROWORK_ACTIVE_NOTEBOOK']:\n",
    "        metadata['generating_script'] = VAR_REGISTRY['REPROWORK_ACTIVE_NOTEBOOK']\n",
    "    else:\n",
    "        metadata['generating_script'] = inspect_filename\n",
    "\n",
    "    '''\n",
    "    # detect if content var is of matplotlib or seaborn object type\n",
    "    if type(content).__name__ in ['Figure', 'AxesSubplot'] and 'savefig' in dir(content):\n",
    "        print('Saving serialized plot to SVG as file and in local data registry.')\n",
    "        # Serialize plot to SVG\n",
    "        buffer = io.BytesIO()\n",
    "        content.savefig(buffer, format='svg')\n",
    "        svg_data = buffer.getvalue()\n",
    "        buffer.close()\n",
    "\n",
    "        # Save SVG to file\n",
    "        svg_filename = filename.replace('.py', '.svg')\n",
    "        with open(svg_filename, 'wb') as file:\n",
    "            file.write(svg_data)\n",
    "\n",
    "        # Save SVG to registry\n",
    "        metadata['plot'] = svg_data.decode()\n",
    "    '''\n",
    "\n",
    "    base_config = read_base_config()\n",
    "    metadata.update(new_metadata)\n",
    "\n",
    "    metadata['value'] = content\n",
    "\n",
    "    # Save content to the default pubdata.toml file\n",
    "    #with open(Path(reproduce_dir, 'pubdata.toml'), 'a') as file:\n",
    "    #    file.write(f'\\n[{name}]\\n')\n",
    "    #    file.write(toml.dumps(content, encoder=ReproduceWorkEncoder()))\n",
    "\n",
    "\n",
    "    # For this demo, let's return the metadata (in practice, you might want to log it, save it to another file, etc.)\n",
    "    if watch:\n",
    "        update_watched_files(add=[Path(reproduce_dir, 'pubdata.toml').resolve().as_posix()])\n",
    "\n",
    "    # check if dynamic file exists\n",
    "    if not os.path.exists(Path(base_config['repro']['files']['dynamic'])):\n",
    "        with open(Path(base_config['repro']['files']['dynamic']), 'w') as file:\n",
    "            file.write(toml.dumps({}))\n",
    "\n",
    "    with open(Path(base_config['repro']['files']['dynamic']), 'r') as file:\n",
    "        dynamic_data = toml.load(file)\n",
    "        \n",
    "    dynamic_data[name] = metadata\n",
    "\n",
    "    with open(Path(base_config['repro']['files']['dynamic']), 'w') as file:\n",
    "        toml.dump(dynamic_data, file, encoder=ReproduceWorkEncoder())\n",
    "\n",
    "    #return metadata\n",
    "    \n",
    "\n",
    "@requires_config\n",
    "def publish_file(filename, metadata={}, watch=True):\n",
    "    \"\"\"\n",
    "    Save content to a file and register metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    # Capture metadata\n",
    "    timestamp = datetime.datetime.now().isoformat()\n",
    "    inspect_filename = inspect.currentframe().f_back.f_code.co_filename\n",
    "    #python_version = sys.version.strip().replace('\\n', ' ')\n",
    "    #platform_info = platform.platform()\n",
    "\n",
    "    # generate cryptographic hash of file contents\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        content = file.read()\n",
    "    content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()\n",
    "    timed_hash = hashlib.md5((content + timestamp).encode('utf-8')).hexdigest()\n",
    "         \n",
    "    #save_context, definition_context = check_for_defintion_in_context(function_name='save')\n",
    "\n",
    "    # Store metadata\n",
    "    new_metadata = {\n",
    "        \"type\": \"file\",\n",
    "        \"timestamp\": timestamp,\n",
    "        #\"python_version\": python_version,\n",
    "        #\"platform_info\": platform_info,\n",
    "        \"content_hash\": content_hash,\n",
    "        \"timed_hash\": timed_hash,\n",
    "        #\"save_context\": save_context,\n",
    "        #\"definition_context\": definition_context\n",
    "    }\n",
    "    cell_index = get_cell_index()\n",
    "    if cell_index:\n",
    "        new_metadata[\"cell_index\"] = cell_index\n",
    "\n",
    "    if VAR_REGISTRY['REPROWORK_REMOTE_URL']:\n",
    "        new_metadata['published_url'] = f\"{VAR_REGISTRY['REPROWORK_REMOTE_URL']}/{filename}\"\n",
    "\n",
    "    if VAR_REGISTRY['REPROWORK_ACTIVE_NOTEBOOK']:\n",
    "        new_metadata['generating_script'] = VAR_REGISTRY['REPROWORK_ACTIVE_NOTEBOOK']\n",
    "    else:\n",
    "        new_metadata['generating_script'] = inspect_filename\n",
    "\n",
    "    base_config = read_base_config()\n",
    "    #reproduce_work_watched_files = base_config['repro.files.watch']\n",
    "\n",
    "    metadata.update(new_metadata)\n",
    "\n",
    "    if watch:\n",
    "        update_watched_files(add=[filename])\n",
    "\n",
    "    # check if dynamic file exists\n",
    "    if not os.path.exists(Path(base_config['repro']['files']['dynamic'])):\n",
    "        with open(Path(base_config['repro']['files']['dynamic']), 'w') as file:\n",
    "            file.write(toml.dumps({}))\n",
    "\n",
    "    with open(Path(base_config['repro']['files']['dynamic']), 'r') as file:\n",
    "        dynamic_data = toml.load(file)\n",
    "\n",
    "    dynamic_data[filename] = metadata\n",
    "\n",
    "    with open(Path(base_config['repro']['files']['dynamic']), 'w') as file:\n",
    "        toml.dump(dynamic_data, file, encoder=ReproduceWorkEncoder())\n",
    "\n",
    "    if 'verbosity' in base_config['repro'] and base_config['repro']['verbose']:\n",
    "        print(f\"Added metadata for file {filename} to dynamic file {base_config['repro']['files']['dynamic']}\")\n",
    "\n",
    "    #return metadata\n",
    "\n",
    "\n",
    "\n",
    "def reproducible(var_assignment_func):\n",
    "    \"\"\"\n",
    "    A decorator to register the line number and timestamp when a variable is assigned.\n",
    "    \"\"\"\n",
    "    @functools.wraps(var_assignment_func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Extract value and var_name from args\n",
    "        # Assumes the decorated function always takes at least two arguments: value and var_name\n",
    "        value, var_name = args[0], args[1]\n",
    "\n",
    "        # Extract metadata from kwargs or default to an empty dictionary\n",
    "        metadata = kwargs.get('metadata', {})\n",
    "\n",
    "        # Get the current frame and line number\n",
    "        frame = inspect.currentframe()\n",
    "        line_number = frame.f_back.f_lineno\n",
    "\n",
    "        # Get the current timestamp\n",
    "        timestamp = datetime.datetime.now().isoformat()\n",
    "\n",
    "        # Get the filename of the caller\n",
    "        filename = frame.f_back.f_code.co_filename\n",
    "\n",
    "        # Execute the variable assignment function\n",
    "        result = var_assignment_func(*args, **kwargs)\n",
    "\n",
    "        # Register the variable name, line number, timestamp, and filename\n",
    "        VAR_REGISTRY[var_name] = {\n",
    "            \"type\": \"string\",\n",
    "            \"timestamp\": timestamp,\n",
    "        }\n",
    "\n",
    "        if type(value) is not str:\n",
    "            value = str(value)\n",
    "            print(f\"WARNING: value of {var_name} was not a string. Converted to string: {value}.\")\n",
    "\n",
    "        VAR_REGISTRY[var_name]['value'] = value\n",
    "\n",
    "        metadata.update(VAR_REGISTRY[var_name])\n",
    "        \n",
    "        if VAR_REGISTRY['REPROWORK_REMOTE_URL']:\n",
    "            metadata['published_url'] = f\"{VAR_REGISTRY['REPROWORK_REMOTE_URL']}/{reproduce_dir}/pubdata.toml\"\n",
    "\n",
    "        if VAR_REGISTRY['REPROWORK_ACTIVE_NOTEBOOK']:\n",
    "            metadata['generating_script'] = VAR_REGISTRY['REPROWORK_ACTIVE_NOTEBOOK']\n",
    "\n",
    "        config = read_base_config()\n",
    "\n",
    "        # check if dynamic file exists\n",
    "        if not os.path.exists(Path(config['repro']['files']['dynamic'])):\n",
    "            with open(Path(config['repro']['files']['dynamic']), 'w') as file:\n",
    "                file.write(toml.dumps({}))\n",
    "        with open(Path(config['repro']['files']['dynamic']), 'r') as file:\n",
    "            dynamic_data = toml.load(file)\n",
    "\n",
    "        dynamic_data[var_name] = metadata\n",
    "\n",
    "        with open(Path(config['repro']['files']['dynamic']), 'w') as file:\n",
    "            toml.dump(dynamic_data, file, encoder=ReproduceWorkEncoder())\n",
    "\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@reproducible\n",
    "def publish_variable(value, var_name, metadata={}):\n",
    "    globals()[var_name] = value\n",
    "\n",
    "\n",
    "@requires_config\n",
    "def register_notebook(notebook_name, notebook_dir='nbs'):\n",
    "    \"\"\"\n",
    "    Register a notebook to the config.toml file.\n",
    "    \"\"\"\n",
    "    notebook_path = notebook_dir + '/' + notebook_name\n",
    "    base_config = read_base_config()\n",
    "    \n",
    "    # ensure notebook key exists\n",
    "    if 'notebooks' not in base_config['repro']:\n",
    "        base_config['repro']['notebooks'] = []\n",
    "\n",
    "    if notebook_path not in base_config['repro']['notebooks']:\n",
    "        base_config['repro']['notebooks'].append(notebook_path)\n",
    "        with open(Path(reproduce_dir, 'config.toml'), 'w') as f:\n",
    "            toml.dump(base_config, f)\n",
    "        if base_config['repro']['verbose']:\n",
    "            print(f\"Registered notebook {notebook_path} in {reproduce_dir}/config.toml\")\n",
    "    else:\n",
    "        if base_config['repro']['verbose']:\n",
    "            print(f\"Notebook {notebook_path} already registered in {reproduce_dir}/config.toml\")\n",
    "\n",
    "    if 'github_repo' in base_config['project']:\n",
    "        remote_url_val = f\"https://github.com/{base_config['project']['github_repo']}\"\n",
    "        notebook_new_val = f\"{remote_url_val}/{notebook_path}\"\n",
    "    else:\n",
    "        notebook_new_val = Path(notebook_path).resolve().as_posix()\n",
    "    \n",
    "    if VAR_REGISTRY['REPROWORK_REMOTE_URL']:\n",
    "        print(f\"Warning: {VAR_REGISTRY['REPROWORK_REMOTE_URL']} is already registered. Overwriting with {remote_url_val}\")\n",
    "    VAR_REGISTRY['REPROWORK_REMOTE_URL'] = remote_url_val\n",
    "\n",
    "    if VAR_REGISTRY['REPROWORK_ACTIVE_NOTEBOOK']:\n",
    "        print(f\"Warning: Notebook {VAR_REGISTRY['REPROWORK_ACTIVE_NOTEBOOK']} is already registered. Overwriting with {notebook_new_val}\")\n",
    "    VAR_REGISTRY['REPROWORK_ACTIVE_NOTEBOOK'] = notebook_new_val\n",
    "\n",
    "    return True\n",
    "\n",
    "# Test code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.kernel.execute('current_cell_index = ' + IPython.notebook.get_selected_index())",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: value of test_var_timestamp_1 was not a string. Converted to string: 67890.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "IPython.notebook.kernel.execute('current_cell_index = ' + IPython.notebook.get_selected_index())",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_var_timestamp_1': {'type': 'string',\n",
       "  'timestamp': '2023-10-02T11:20:32.483177',\n",
       "  'value': '67890'},\n",
       " 'test_var_timestamp_2': {'type': 'string',\n",
       "  'timestamp': '2023-10-02T11:20:32.506332',\n",
       "  'value': 'Hello again!'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish_variable(67890, \"test_var_timestamp_1\")  # This should capture this line number and timestamp\n",
    "publish_variable(\"Hello again!\", \"test_var_timestamp_2\")  # And this line number and timestamp\n",
    "\n",
    "VAR_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = \"John\"\n",
      "age = 28\n",
      "is_student = False\n",
      "scores = [85, 90, 78, 92]\n",
      "birthday = \"2000-01-01 00:00:00\"\n",
      "[df]\n",
      "[dataframe]\n",
      "A = [1, 2, 3]\n",
      "B = [\"a\", \"b\", \"c\"]\n",
      "date = [\"2022-01-01 00:00:00\", \"2022-01-02 00:00:00\", \"2022-01-03 00:00:00\"]\n",
      "\n",
      "[nested_dict]\n",
      "key1 = \"value1\"\n",
      "[sub_dict]\n",
      "sub_key = \"sub_value\"\n",
      "\n",
      "\n",
      "none_value = null\n"
     ]
    }
   ],
   "source": [
    "# Test the serialize_to_toml function\n",
    "data_sample = {\n",
    "    'name': 'John',\n",
    "    'age': 28,\n",
    "    'is_student': False,\n",
    "    'scores': [85, 90, 78, 92],\n",
    "    'birthday': pd.Timestamp('2000-01-01'),\n",
    "    'matrix': np.array([[1, 2], [3, 4]]),\n",
    "    'df': pd.DataFrame({\n",
    "        'A': [1, 2, 3],\n",
    "        'B': ['a', 'b', 'c'],\n",
    "        'date': [pd.Timestamp('2022-01-01'), pd.Timestamp('2022-01-02'), pd.Timestamp('2022-01-03')]\n",
    "    }),\n",
    "    'nested_dict': {\n",
    "        'key1': 'value1',\n",
    "        'sub_dict': {\n",
    "            'sub_key': 'sub_value'\n",
    "        }\n",
    "    },\n",
    "    'none_value': None\n",
    "}\n",
    "\n",
    "toml_representation = serialize_to_toml(data_sample)\n",
    "print(toml_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[p_value_str]\n",
      "description = \"The p-value of the coefficient on the slope of the linear regression line.\"\n",
      "type = \"string\"\n",
      "timestamp = \"2023-10-02T10:25:50.962908\"\n",
      "value = \"0.068\"\n",
      "\n",
      "[x]\n",
      "description = \"The simulated X data\"\n",
      "units = \"kilograms\"\n",
      "type = \"data\"\n",
      "timestamp = \"2023-10-02T10:25:51.146421\"\n",
      "content_hash = \"38f13b81a58a7d931600e917d77dfe8f\"\n",
      "timed_hash = \"1ff88e55c506ce6249051526f0071e20\"\n",
      "value = \"array = [-0.15438854676085806, -0.5912841266673995, 1.3457620267806991, -0.3085476927297975, -0.35074090433304067, -1.343721369940541, -0.41860346256356656, 2.392890531248967, 0.22032854237060082, 0.7867023188803995, 0.08878384294999392, 0.6565087673201803, 0.2412729155438198, 0.6854353883101262, 2.153899580706892, 0.649925720150528, 1.127458119203137, -0.6357927443286684, 0.3077660698412044, -1.6328895355458346, 0.567227693439327, -0.21246173380662106, -0.7203897514131021, 0.5952129857137533, 0.18819499630282482, -0.8834998061258611, 0.7379945086294778, -0.8471634166162177, 0.07930983762624676, -0.10076438386878037, 0.4738798861563753, -0.10847987920496371, -1.16728052821831, 0.19401114268043276, -1.8697690072012825, -0.6079795737042001, -0.46088161234713115, 2.8744072140185186, 0.5779526555390606, 0.18642158999690325, -2.309463070393277, 0.9160646628168791, -0.036987499173112684, -0.6186664971219734, -0.7375207406586269, -0.3364114042058939, 0.6487550984010515, 0.7211593530346008, -3.0024570001024453, 0.20827750750261484, -0.9184527060704434, -0.5672153127477911, 0.31933453622980007, -0.37561851948771674, -0.11011613613998829, -2.5786876868233346, -2.2352575258690286, -0.14238353838147055, -0.7776623814911557, -0.12899276868200904, 0.821021437212202, 0.18632478617667347, 1.6469255261436233, 0.30333446984835577, -0.2888772687627644, 0.4875026119003026, 0.2806902509255848, -0.7998526623370962, 0.5301005871453163, 0.6998691293042977, -0.08461487877674735, -0.6322047366002711, -0.9348762425303966, -0.3857949711398192, 0.7758631517211686, 1.522836840694002, 0.25484897092674863, 2.0472839024926945, -0.548936278321665, 0.34845246870820656, -1.7722932107691587, 1.888704309449281, -1.1123418283924837, 1.3957453427395787, -0.8294367151092402, -1.1699534011438901, 1.0257270873514317, 0.7725006923281748, 0.3168385924779005, -0.30234878342901056, -0.1751641272612662, 0.3708234523019773, -2.3638133220013833, -0.4096668642141042, -0.4503293983368002, 0.03271836277038858, -1.4370887475738319, 0.19926882906384208, -0.08950771441073352, 0.4128495165175878]\\n\"\n",
      "\n",
      "[y]\n",
      "description = \"The simulated Y data\"\n",
      "units = \"meters\"\n",
      "type = \"data\"\n",
      "timestamp = \"2023-10-02T10:25:51.678260\"\n",
      "content_hash = \"f8945d4c03988df0cd59c181035e86a9\"\n",
      "timed_hash = \"a306a63a68be7c4f84373afa6f4aee18\"\n",
      "value = \"array = [6.157526466969694, -9.302292211258417, -13.445653295124679, -8.631538800322812, 6.90483152433306, 5.207550454217913, 0.16281392537419195, 11.328419829563888, 22.478972058029154, 8.09134242274941, 5.073777096618679, 10.521865081855475, -16.790794925289998, -8.771064388620061, 4.0201332562739776, 5.117579323047639, 7.625083590549531, 3.8773345015463985, -3.928796702192886, -14.12618901867805, 15.719046636739415, -6.9901326969788835, -1.2697524315402995, 16.200579300476225, 4.653298124929337, 15.260286007217859, -8.66974802826228, 17.391748658118644, -11.979777143905922, -9.165369928333158, -10.066499099879193, 6.630265916533632, 5.597192274467069, 21.121094702481354, -0.37289209663747613, -10.093484219122008, -6.178013487751987, 4.612879529582713, -6.7221265756959445, 1.5429361341495342, -15.542297438913536, -6.9087508309560315, -5.756954497072782, 0.9567354246293611, -14.214770323986233, -12.709171551566424, 4.786356565840399, -4.890780892875197, -3.6073631505593395, 7.0359632267386765, -0.24241139306973603, -3.9167058403914647, 16.71776645328651, -14.815178430705346, -1.711860745824135, -10.08015043115352, -13.900633437259023, -27.590693317580115, 2.4225289380487824, 0.4100939029862429, -14.009201312069894, 26.99576623694627, 8.292226202794245, -16.51426094603318, -2.931299487241554, -3.06749774639879, -2.457980870324348, -11.765930634755847, -1.7957980955875312, 3.947583774063118, 1.7788813956475347, -1.513133427837522, 21.831572921844153, 7.891774924891347, -6.6299731645332045, 14.88059560881568, -14.321343993977925, 4.842025745064475, -18.45138246049829, -2.5286695131892367, 26.92858990370225, 14.990430393073257, -6.687320844036032, -6.3145713683066536, -1.865395572103326, 0.29997911599165183, 2.094399418593174, 5.231357076332482, -10.36763582996726, 1.6895152163357683, 6.181719576405759, -10.030869854369993, -14.337403366313984, 6.834137681527773, 7.186270591613762, -1.9468050084023705, 9.311246589228013, 0.08957849212100343, -4.817637123369896, 7.997470135737686]\\n\"\n",
      "\n",
      "[\"reproducible_plot.svg\"]\n",
      "description = \"A plot of X vs Y\"\n",
      "type = \"file\"\n",
      "timestamp = \"2023-10-02T10:25:52.305297\"\n",
      "content_hash = \"bb296f59053ba6d7cccea638b3edcf52\"\n",
      "timed_hash = \"09b3a1eaf7be868f20636e0ce8325570\"\n",
      "\n",
      "[test_var_timestamp_1]\n",
      "type = \"string\"\n",
      "timestamp = \"2023-10-02T11:20:32.483177\"\n",
      "value = \"67890\"\n",
      "\n",
      "[test_var_timestamp_2]\n",
      "type = \"string\"\n",
      "timestamp = \"2023-10-02T11:20:32.506332\"\n",
      "value = \"Hello again!\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = read_base_config()\n",
    "with open(config['repro']['files']['dynamic'], 'r') as file:\n",
    "    dynamic_data = toml.load(file)\n",
    "print(toml.dumps(dynamic_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the save function\n",
    "test_content = \"This is a test content for the save function.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.kernel.execute('current_cell_index = ' + IPython.notebook.get_selected_index())",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated watched files to ['reproduce/main.md', 'reproduce/data.toml', 'reproduce/latex/template.tex', 'saved_file.txt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'file',\n",
       " 'timestamp': '2023-10-02T02:11:11.082654',\n",
       " 'content_hash': 'd1866c6aa7d10eb57a35cc88a77802c5',\n",
       " 'timed_hash': 'f9293765bd6cc1e991407203aa7da511'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = save(test_content, \"saved_file.txt\")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "#x = 10\n",
    "#y = \"Hello\"\n",
    "#z = [1, 2, 3]\n",
    "#save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
